{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fic-gS4fWzBt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import joblib\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Displaying stopwords\n",
        "# print(stopwords.words('english'))\n",
        "\n",
        "# Loading in data and naming columns to original names as in the dataset\n",
        "dataset = \"/content/dataset.csv\"\n",
        "\n",
        "naming_col = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
        "\n",
        "data = pd.read_csv(dataset, names=naming_col, encoding='latin1')\n",
        "\n",
        "# print(data.columns)\n",
        "\n",
        "# Renaming columns\n",
        "data.columns = ['sentiment', 'id', 'date', 'query', 'user', 'tweet']\n",
        "\n",
        "print(\"Done renaming column names\")\n",
        "\n",
        "# print(data.columns)\n",
        "# print(data.head())\n",
        "\n",
        "# Checking for any null values\n",
        "# data.isnull().sum()\n",
        "# print(data.shape)\n",
        "\n",
        "# Number of distributions for positive and negative values\n",
        "print(data['sentiment'].value_counts())\n",
        "\n",
        "# sentiment\n",
        "# 0    800000 Negative values\n",
        "# 4    800000 Positive values\n",
        "\n",
        "data.isnull().sum()\n",
        "\n",
        "# Replacing 4 with 1 (assigning positive sentiment the value of 1)\n",
        "data.replace({'sentiment': {4: 1}}, inplace=True)\n",
        "print(data['sentiment'].value_counts())\n",
        "\n",
        "print(\"Done setting 0 and 1 to negative and positive\")\n",
        "\n",
        "# sentiment\n",
        "# 0    800000 Negative values\n",
        "# 1    800000 Positive values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y8ap8e_Ve7Ko",
        "outputId": "3c79ba0b-5011-41e1-a0d1-2a630d941acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done stemming!\n"
          ]
        }
      ],
      "source": [
        "# Stemming words with NLTK\n",
        "# https://www.geeksforgeeks.org/python-stemming-words-with-nltk/\n",
        "'''\n",
        "Stemming is the process of producing morphological variants of a root/base word.\n",
        "Some examples of stemming for root word \"like\" include:\n",
        "\n",
        "-> \"likes\"\n",
        "-> \"liked\"\n",
        "-> \"likely\"\n",
        "-> \"liking\"\n",
        "'''\n",
        "\n",
        "# Stemming object\n",
        "ps = PorterStemmer()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to stem all words in the tweet\n",
        "def stemming(content):\n",
        "\n",
        "    # Removes every letter in the content that is not a to z letters\n",
        "    stemmed = re.sub('[^a-zA-Z]', ' ', content)\n",
        "    stemmed = stemmed.lower()\n",
        "    stemmed = stemmed.split()\n",
        "\n",
        "    # How many words are stemmed\n",
        "    stemmed_count = 0\n",
        "\n",
        "    stemmed = [ps.stem(word) for word in stemmed if not word in stop_words]\n",
        "\n",
        "    stemmed = ' '.join(stemmed)\n",
        "\n",
        "    return stemmed\n",
        "\n",
        "\n",
        "# Adding a new column called stemmed in the dataset to\n",
        "data['stemmed'] = data['tweet'].apply(stemming)\n",
        "\n",
        "print(\"Done stemming!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTYFDeljm9UE",
        "outputId": "5b8a5c10-93ab-4377-81dc-2d84d82c1795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done splitting\n",
            "Done vectorizing\n",
            "Training\n"
          ]
        }
      ],
      "source": [
        "# Feature and target split\n",
        "feature = data['stemmed'].values\n",
        "target = data['sentiment'].values\n",
        "\n",
        "# Train and test split of feature and target variables\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size=0.2, stratify=target, random_state=42)\n",
        "\n",
        "print(\"Done splitting\")\n",
        "\n",
        "# Vectorizer to convert raw data to matrix of TF-IDF features\n",
        "# https://stats.stackexchange.com/questions/154660/tfidfvectorizer-should-it-be-used-on-train-only-or-traintest\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Vectorizing test and training feature variables\n",
        "X_train = vectorizer.fit_transform(X_train.tolist())\n",
        "X_test = vectorizer.transform(X_test.tolist())\n",
        "\n",
        "print(\"Done vectorizing\")\n",
        "\n",
        "# Logistic regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "print(\"Training\")\n",
        "\n",
        "# Train model\n",
        "logistic_model.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Done training!\")\n",
        "\n",
        "X_train_pred = logistic_model.predict(X_train)\n",
        "acc = accuracy_score(Y_train, X_train_pred)\n",
        "\n",
        "print(\"Train Accuracy:\", acc)\n",
        "\n",
        "X_test_pred = logistic_model.predict(X_test)\n",
        "test_acc = accuracy_score(Y_test, X_test_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "joblib.dump(logistic_model, '/content/model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Gz-J4TyMAC",
        "outputId": "55cf1377-e8b3-4871-8ddd-c85b3bf16d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.77    160000\n",
            "           1       0.77      0.80      0.78    160000\n",
            "\n",
            "    accuracy                           0.78    320000\n",
            "   macro avg       0.78      0.78      0.78    320000\n",
            "weighted avg       0.78      0.78      0.78    320000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print('Classification report')\n",
        "print(classification_report(Y_test, X_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE5idhBZymM9"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}